{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Self Study 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this self study we perform character recognition using SVM classifiers. We use the MNIST dataset, which consists of 70000 handwritten digits 0..9 at a resolution of 28x28 pixels. \n",
    "\n",
    "Stuff we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from skimage.transform import rescale, resize\n",
    "#from sklearn.datasets import fetch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the MNIST data. Using the fetch_mldata function, this will be downloaded from the web, and stored in the directory you specify as data_home (replace my path in the following cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(name='mnist_784', data_home='/home/jaeger/Data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has .data and .target attributes. The following gives us some basic information on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 70000\n",
      "\n",
      "Number of features: 784\n",
      "\n",
      "List of labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of datapoints: {}\\n\".format(mnist.data.shape[0]))\n",
    "print(\"Number of features: {}\\n\".format(mnist.data.shape[1]))\n",
    "print(\"List of labels: {}\\n\".format(np.unique(mnist.target)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist.data is represented as a Pandas dataframe. The following code expects mnist.data to be a plain np.array, which we get simply by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data=np.array(mnist.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot individual datapoints as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of datapoint no. 4:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  55. 148.\n",
      " 210. 253. 253. 113.  87. 148.  55.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  87. 232. 252.\n",
      " 253. 189. 210. 252. 252. 253. 168.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.  57. 242. 252. 190.\n",
      "  65.   5.  12. 182. 252. 253. 116.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  96. 252. 252. 183.  14.\n",
      "   0.   0.  92. 252. 252. 225.  21.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 132. 253. 252. 146.  14.   0.\n",
      "   0.   0. 215. 252. 252.  79.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 126. 253. 247. 176.   9.   0.   0.\n",
      "   8.  78. 245. 253. 129.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  16. 232. 252. 176.   0.   0.   0.  36.\n",
      " 201. 252. 252. 169.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  22. 252. 252.  30.  22. 119. 197. 241.\n",
      " 253. 252. 251.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  16. 231. 252. 253. 252. 252. 252. 226.\n",
      " 227. 252. 231.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  55. 235. 253. 217. 138.  42.  24.\n",
      " 192. 252. 143.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  62.\n",
      " 255. 253. 109.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  71.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  71.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 106.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  45.\n",
      " 255. 253.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 218. 252.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  96. 252. 189.  42.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  14. 184. 252. 170.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  14. 147. 252.  42.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "\n",
      "As image:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4\n",
    "print(\"Value of datapoint no. {}:\\n{}\\n\".format(index,mnist.data[index]))\n",
    "print(\"As image:\\n\")\n",
    "plt.imshow(mnist.data[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things a little bit simpler (and faster!), we can extract from the data binary subsets, that only contain the data for two selected digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint now is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 14117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digit0='4'\n",
    "digit1='7'\n",
    "mnist_bin_data=mnist.data[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "mnist_bin_target=mnist.target[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "print(\"The first datapoint now is: \\n\")\n",
    "plt.imshow(mnist_bin_data[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(\"Number of datapoints: {}\\n\".format(len(mnist_bin_data)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Split the mnist_bin data into training and test set. Learn different SVM models by varying the kernel functions (SVM). For each configuration, determine the time it takes to learn the model, and the accuracy on the test data. \n",
    "\n",
    "You can get the current time using:\n",
    "\n",
    "`import time` <br>\n",
    "`now = time.time()`\n",
    "\n",
    "*Caution*: for some configurations, learning here can take a little while (several minutes).\n",
    "\n",
    "Using the numpy where() function, one can extract the indices of the test cases that were misclassified: <br>\n",
    "`misclass = np.where(test != predictions)` <br>\n",
    "Inspect some misclassified cases. Do they correspond to hard to recognize digits (also for the human reader)? \n",
    "\n",
    "How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "Identify one or several good configurations that give a reasonable combination of accuracy and runtime. Use these configurations to perform a full classification of the 10 classes in the original dataset (after split into train/test). Using `sklearn.metrics.confusion_matrix` you can get an overview of all combinations of true and predicted labels. What does this tell you about which digits are easy, and which ones are difficult to recognize, and which ones are most easily confused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9881 4236\n",
      "9881 4236\n"
     ]
    }
   ],
   "source": [
    "is_all_data = False\n",
    "mnist_bin = lambda : None\n",
    "if is_all_data:\n",
    "    mnist_bin.data = mnist.data\n",
    "    mnist_bin.target = mnist.target\n",
    "else:\n",
    "    mnist_bin.data = mnist_bin_data\n",
    "    mnist_bin.target = mnist_bin_target\n",
    "\n",
    "data_training, data_test, target_training, target_test = sklearn.model_selection.train_test_split(mnist_bin.data, mnist_bin.target, test_size=0.30, train_size=0.70, random_state=None, shuffle=True, stratify=None)\n",
    "\n",
    "print(len(data_training), len(data_test))\n",
    "print(len(target_training), len(target_test))\n",
    "\n",
    "mnist_bin.data_training = data_training\n",
    "mnist_bin.data_test = data_test\n",
    "mnist_bin.target_training = target_training\n",
    "mnist_bin.target_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9881, 784)\n",
      "linear:: Time difference: 3.35465407371521 sec; Train Accuracy: 1.0; Test Accuracy: 0.983947119924457\n",
      "[[2029   35]\n",
      " [  33 2139]]\n",
      "(9881, 784)\n",
      "rbf:: Time difference: 3.958343982696533 sec; Train Accuracy: 0.9972674830482745; Test Accuracy: 0.9974032105760151\n",
      "[[2062    2]\n",
      " [   9 2163]]\n",
      "(9881, 784)\n",
      "poly:: Time difference: 3.9288153648376465 sec; Train Accuracy: 0.9986843436899099; Test Accuracy: 0.997639282341832\n",
      "[[2061    3]\n",
      " [   7 2165]]\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "def calculate_kernel_time(kernel_id):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = SVC(kernel=kernel_id)\n",
    "\n",
    "    print(mnist_bin.data_training.shape)\n",
    "    model.fit(mnist_bin.data_training, mnist_bin.target_training)\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, model\n",
    "\n",
    "def get_train_acc(model):\n",
    "    return sklearn.metrics.accuracy_score(mnist_bin.target_training, model.predict(mnist_bin.data_training))\n",
    "\n",
    "def get_test_acc(model):\n",
    "    return sklearn.metrics.accuracy_score(mnist_bin.target_test, model.predict(mnist_bin.data_test))\n",
    "\n",
    "for kernel in kernels:\n",
    "    linear_time_diff, model = calculate_kernel_time(kernel)\n",
    "    train_acc = get_train_acc(model)\n",
    "    accuracy = get_test_acc(model)\n",
    "    print(f\"{kernel}:: Time difference: {linear_time_diff} sec; Train Accuracy: {train_acc}; Test Accuracy: {accuracy}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(mnist_bin.target_test, model.predict(mnist_bin.data_test))\n",
    "    print(conf_matrix)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** In the experiments done in Exercise 1 you applied generic \"off-the-shelf\" kernels to the original data representation given by a 28 x 28 matrix. Can you think of other data transformations that are more directly targeted at constructing features that are informative for the character recognition task (remember e.g. the exercise from last week to construct features for making the x-or data linearly separable)? You should consider the following two approaches:<br>\n",
    "\n",
    "**a)** Manually design feature functions for which you expect that based on your new features SVM classifiers can achieve a better accuracy than with the original features (ideally, given the new features, only a linear SVM then is needed). Transform the data into your new feature space, and learn new classifiers. What accuracies do you get? It is not expected that you get higher accuracies than with the best SVM from Exercise 1. What you should aim for is that you get better accuracies when you apply a linear SVM to your transformed data, than when you apply a linear SVM to the original data.\n",
    "\n",
    "**b)** Instead of designing an explicit feature mapping as in **a)**, define a suitable measure of similarity for the digits, and implement that measure as a kernel function. (Optional: verify that the function you have defined actually satisfies the positive-semidefiniteness property.) Use your kernel function as a custom kernel for the SVC classifier.  See http://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mnist_bin.data_training[0].shape)\n",
    "# print(resize(mnist_bin.data_training[0], (32, 32), anti_aliasing=True).shape)\n",
    "\n",
    "# print(mnist_bin.data_training.shape)\n",
    "# print(mnist_bin.data_test.shape)\n",
    "# mnist_bin.data_training = np.array([resize(image, (32, 32), anti_aliasing=True) for image in mnist_bin.data_training])\n",
    "# mnist_bin.data_test = np.array([resize(image, (32, 32), anti_aliasing=True) for image in mnist_bin.data_test])\n",
    "\n",
    "# mnist_bin.data_training = mnist_bin.data_training.reshape(-1, 1024)\n",
    "# mnist_bin.data_test = mnist_bin.data_test.reshape(-1, 1024)\n",
    "\n",
    "# print(mnist_bin.data_training.shape)\n",
    "# print(mnist_bin.data_test.shape)\n",
    "\n",
    "# for kernel in kernels:\n",
    "#     linear_time_diff, model = calculate_kernel_time(kernel)\n",
    "#     train_acc = get_train_acc(model)\n",
    "#     accuracy = get_test_acc(model)\n",
    "#     print(f\"{kernel}:: Time difference: {linear_time_diff} sec; Train Accuracy: {train_acc}; Test Accuracy: {accuracy}\")\n",
    "\n",
    "#     conf_matrix = confusion_matrix(mnist_bin.target_test, model.predict(mnist_bin.data_test))\n",
    "#     print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly:: Time difference: 3.9288153648376465 sec; Train Accuracy: 1.0; Test Accuracy: 0.9978753541076487\n",
      "[[2062    2]\n",
      " [   7 2165]]\n"
     ]
    }
   ],
   "source": [
    "def squared_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)**2\n",
    "\n",
    "model = SVC(kernel=squared_kernel)\n",
    "model.fit(mnist_bin.data_training, mnist_bin.target_training)\n",
    "\n",
    "train_acc = get_train_acc(model)\n",
    "accuracy = get_test_acc(model)\n",
    "\n",
    "print(f\"{kernel}:: Time difference: {linear_time_diff} sec; Train Accuracy: {train_acc}; Test Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(mnist_bin.target_test, model.predict(mnist_bin.data_test))\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SKOLE\\Guthub\\ML23\\Recooking\\SelfStudy3.ipynb Cell 20\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m K\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39mbest_kernel)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(mnist_bin\u001b[39m.\u001b[39;49mdata_training, mnist_bin\u001b[39m.\u001b[39;49mtarget_training)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m train_acc \u001b[39m=\u001b[39m get_train_acc(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy \u001b[39m=\u001b[39m get_test_acc(model)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:255\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 255\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    256\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:297\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m    294\u001b[0m     \u001b[39m# you must store a reference to X to compute the kernel in predict\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[39m# TODO: add keyword copy to copy on demand\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__Xfit \u001b[39m=\u001b[39m X\n\u001b[1;32m--> 297\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_kernel(X)\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m    300\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mX.shape[0] should be equal to X.shape[1]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:493\u001b[0m, in \u001b[0;36mBaseLibSVM._compute_kernel\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m    491\u001b[0m     \u001b[39m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[0;32m    492\u001b[0m     \u001b[39m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__Xfit)\n\u001b[0;32m    494\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(kernel):\n\u001b[0;32m    495\u001b[0m         kernel \u001b[39m=\u001b[39m kernel\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[1;32md:\\SKOLE\\Guthub\\ML23\\Recooking\\SelfStudy3.ipynb Cell 20\u001b[0m in \u001b[0;36mbest_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(X):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j, y \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(Y):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         K[i, j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x \u001b[39m-\u001b[39;49m y) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SKOLE/Guthub/ML23/Recooking/SelfStudy3.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m K\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:2511\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2509\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2511\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[0;32m   2512\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2513\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def best_kernel(X, Y, gamma=0.5):\n",
    "    K = np.zeros((X.shape[0], Y.shape[0]))\n",
    "    for i, x in enumerate(X):\n",
    "        for j, y in enumerate(Y):\n",
    "            K[i, j] = np.exp(-gamma * np.linalg.norm(x - y) ** 2)\n",
    "    return K\n",
    "\n",
    "model = SVC(kernel=best_kernel)\n",
    "model.fit(mnist_bin.data_training, mnist_bin.target_training)\n",
    "\n",
    "train_acc = get_train_acc(model)\n",
    "accuracy = get_test_acc(model)\n",
    "\n",
    "print(f\"{kernel}:: Time difference: {linear_time_diff} sec; Train Accuracy: {train_acc}; Test Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(mnist_bin.target_test, model.predict(mnist_bin.data_test))\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
