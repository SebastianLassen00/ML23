{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344e053-a576-40f2-a88f-9cbf4daeda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared, RationalQuadratic, DotProduct, ConstantKernel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be46fb7-ae03-441a-b766-6d3c2f64dca3",
   "metadata": {},
   "source": [
    "# Part 1: Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b8cd7-8344-468f-ad76-d21999d4712a",
   "metadata": {},
   "source": [
    "Below we implement a couple of kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e99cae-57bc-4866-9000-bdef94b67286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiated_quadratic(xa, xb, sigma=1, length_scale=1):\n",
    "    \"\"\"Exponentiated quadratic  with Ïƒ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * scipy.spatial.distance.cdist(xa, xb, 'sqeuclidean')/length_scale\n",
    "    return (sigma**2) * np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac9eb3-0250-407b-9b64-890c19c023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_kernel(xa, xb, period=1, length_scale=1, sigma=1):\n",
    "    # L1 norm\n",
    "    l1_norm =  scipy.spatial.distance.cdist(xa, xb, 'minkowski', p=1)\n",
    "    return sigma**2 * np.exp(-2/length_scale**2 * (np.sin(np.pi * l1_norm/period)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b94e45-331a-46ec-9ef9-b7f4064dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(xa, xb):\n",
    "    return xa@xb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo_kernel(xa, xb):\n",
    "    return periodic_kernel(xa, xb) * linear_kernel(xa, xb) + exponentiated_quadratic(xa, xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc832153-f781-475c-b397-786b3ea3099e",
   "metadata": {},
   "source": [
    "Let's make a few illustrations following the same theme as in the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea210571-2d02-4af2-936b-9179c7e7c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "num_samples = 5\n",
    "X = np.expand_dims(np.linspace(-4, 4, dim), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd877b85-f1bd-4a04-a975-f0afb6e21f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COV = exponentiated_quadratic(X, X, length_scale=1)\n",
    "COV = combo_kernel(X, X)\n",
    "plt.figure()\n",
    "sns.heatmap(COV, cmap='Blues', xticklabels=False, yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca78b85-5754-42b8-8b1d-c1aca5da4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((COV.shape[0],))\n",
    "x = np.random.multivariate_normal(mean.squeeze(), COV, size=num_samples)\n",
    "for i in range(num_samples):\n",
    "    plt.plot(X.squeeze(), x[i], '-')\n",
    "plt.xlabel(r'$x$', fontsize=13)\n",
    "plt.ylabel(r'$f(x)$', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2e113-309b-48f6-9779-b2e67de8dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, COV[25, :], '-', label=f'$l=${1}')\n",
    "plt.title('Exponentiated quadratic distance plot')\n",
    "plt.xlabel(r'$x_a-x_b$')\n",
    "plt.ylabel(r'$k(x_a,x_b)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36545603-30c2-441e-81d1-e8476433fe2d",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fa05a-bf96-4252-b75f-5e4b7ac23fa3",
   "metadata": {},
   "source": [
    "This exericse is mostly about familiarising yourself with the kernels\n",
    "1. Using the kernel implementations and visualizations above, investigate the effect of changing the kernel parameters.\n",
    "2. Define new kernels using kernel combinations (addition and multiplication). Explore the effect of different combinations and varying kernel parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8f638-2b9d-49fe-b0ae-272277c16864",
   "metadata": {},
   "source": [
    "## Part 2: Self study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edba50-f7ee-4d8f-ad0f-3b83dde0a659",
   "metadata": {},
   "source": [
    "In this exercise we will be experimenting with data on atmosoheric CO2 measurements data from Mauna Loa. You can find additional information about the data from the <a href=\"https://scrippsco2.ucsd.edu/data/atmospheric_co2/primary_mlo_co2_record.html\">here</a>, included the full data set. In this exercise we will be using a slightly cleaned up version of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2290db7-f91a-4132-8c02-da174c538089",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_df = pd.read_csv(\n",
    "    # Source: https://scrippsco2.ucsd.edu/assets/data/atmospheric/stations/in_situ_co2/monthly/monthly_in_situ_co2_mlo.csv\n",
    "    './co2.csv',\n",
    "    header=0, # Data starts here\n",
    "    usecols=[3, 4], # Only keep the 'Date' and 'CO2' columns\n",
    "    na_values='-99.99',  # NaNs are denoted as '-99.99'\n",
    "    dtype=np.float64,\n",
    "    sep=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962847f0-f8a4-4bc5-8ed8-b0db7518154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "co2_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea121e26-5805-40ee-849d-6a456386bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into an observed part and a part we want to make predictions for\n",
    "date_split_predict = 2010\n",
    "df_observed = co2_df[co2_df.Date < date_split_predict]\n",
    "print('{} measurements in the observed set'.format(len(df_observed)))\n",
    "df_predict = co2_df[co2_df.Date >= date_split_predict]\n",
    "print('{} measurements in the test set'.format(len(df_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a820f5b-8162-449b-a0a3-52f5af67828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_observed.iloc[:,0].values, df_observed.iloc[:,1].values)\n",
    "plt.title(\"In situ air measurements at Mauna Loa, Observatory, Hawaii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d382a60-335d-4185-8e64-e4171c3e5b79",
   "metadata": {},
   "source": [
    "Separate out the input data and the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac080737-161e-43b8-99de-16d0058fda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_observed['Date'].values\n",
    "f_train = df_observed['CO2'].values\n",
    "x_test = df_predict['Date'].values\n",
    "f_test = df_predict['CO2'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae497bf3-fc9e-42a3-ac6a-819fdd334e37",
   "metadata": {},
   "source": [
    "Setup a first shot at a kernel. Scikit learn offers a variety of predifed kernels. An overview of the available kernels can be found <a href=\"https://scikit-learn.org/stable/modules/gaussian_process.html#kernels-for-gaussian-processes\">here</a> and a gentle introduction to Gaussian processes in sklearn can be found <a href=\"https://scikit-learn.org/stable/modules/gaussian_process.html#\">here</a>. In particular, it would be a good idea to consult the kernel section to get a better understanding of the kernel specification below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e1156-df8a-49f9-9879-d5706955f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_kernel = 50**2*RBF(length_scale=20) + WhiteKernel(noise_level=5.4, noise_level_bounds=\"fixed\") + (ExpSineSquared(length_scale=1, periodicity=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea18e7b-b06b-46ad-8cf2-6e87d93ceab0",
   "metadata": {},
   "source": [
    "With the kernel specified, we can start a Gaussian process model of our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767eddb3-1878-439e-b9e4-3ba5f047fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = f_train.mean()\n",
    "gaussian_process = GaussianProcessRegressor(kernel=co2_kernel, normalize_y=False)\n",
    "gaussian_process.fit(x_train.reshape(-1,1), f_train - f_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e915c-0dd9-434b-80eb-0f1c58a8fb54",
   "metadata": {},
   "source": [
    "Using our newly learned GP, we can do prediction on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370b878-b1a5-4d7d-b310-f6361922baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f_pred, std_f_pred = gaussian_process.predict(x_test.reshape(-1,1), return_std=True)\n",
    "mean_f_pred += f_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf75d5d-3f22-47ae-b79d-6c3a7e6a8e50",
   "metadata": {},
   "source": [
    "Let's get a feel for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b8217-6a4a-419a-bbbd-22f1e80bd216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, f_train, '-b')\n",
    "plt.plot(x_test, f_test, color=\"tab:blue\", alpha=0.4)\n",
    "plt.plot(x_test, mean_f_pred, '-r')\n",
    "plt.fill_between(\n",
    "    x_test.ravel(),\n",
    "    mean_f_pred - std_f_pred,\n",
    "    mean_f_pred + std_f_pred,\n",
    "    color=\"tab:red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO$_2$ concentration (ppm)\")\n",
    "_ = plt.title(\n",
    "    \"Monthly average of air samples measurements\\nfrom the Mauna Loa Observatory\")\n",
    "plt.show()\n",
    "print(\"christian er noob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3351632-84b4-4ea7-a3d8-18eb1fcd81df",
   "metadata": {},
   "source": [
    "Kernel parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0430a66-794d-4376-9aad-6c0ae95f975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_process.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798f6a7-0b57-4e69-b28c-19ecf7a783c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {np.mean((mean_f_pred - f_test)**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f72d42-5645-47e1-a094-3558c48d3986",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Our Gaussian process model does clearly not do a good job at capturing the evolution in the CO2 measurements. For one thing, it completely ignores the periodicity in the signal.\n",
    "1. Construct a new kernel that better captures the CO2 measurements in the test set\n",
    "2. Use your Gaussian process model to estimate the missing CO2 mesurement values in the dat set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db203dc8-3a70-41a7-8c04-f13526fe1104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
