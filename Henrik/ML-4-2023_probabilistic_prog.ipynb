{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Exercise on plate notation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plate notation can also be used to represented repeated substructure with shared parameters (conditional probability distributions). \n",
    "\n",
    "<img src=\"./skills.png\" alt=\"Drawing\">\n",
    "\n",
    "Assume that we have two students and two course. What does the unfolded models for the two plate models above look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a75mGrGgL-0g"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "# Setup\n",
    "We will now continue with more Pyro relateed exercises. Let's begin by installing and importing the modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Owp2eKrL-0j"
   },
   "outputs": [],
   "source": [
    "#!pip install -q --upgrade pyro-ppl torch\n",
    "import pyro\n",
    "import torch\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\">Exercise introduction</span>**\n",
    "\n",
    "The main goal with the exercises below is to get some experience with probabilistic modeling. Here we exemplify modeling using Pyro, but any other probabilistic programming language could also have been used.\n",
    "\n",
    "There are two explicit exercises embedded in this notebook (marked with red as above). Before working on these exercises, step carefully through the notebook leading up to the exercises and make sure that you have a good understanding on what is done in the individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-EvHtlvL-0k"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "# 1. **Pyro’s distributions**:\n",
    "\n",
    "\n",
    "Pyro provides a wide range of distributions: **Normal, Beta, Cauchy, Dirichlet, Gumbel, Poisson, Pareto, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_w52OifSL-0l",
    "outputId": "f18fed03-42e0-44af-d852-ffc4f11cd71c"
   },
   "outputs": [],
   "source": [
    "normal = dist.Normal(0,1)\n",
    "normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOSdcF4_L-0m"
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "Samples from the distributions are [Pytorch’s Tensor objects](https://pytorch.org/cppdocs/notes/tensor_creation.html) (i.e. multidimensional arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wloQxYMXL-0m",
    "outputId": "272451fe-b15d-4643-e9ff-efcb352cdcbc"
   },
   "outputs": [],
   "source": [
    "sample = normal.sample()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h2iOp-qL-0o",
    "outputId": "8eaffb2b-1e5f-4a15-c388-b3100c75c89c"
   },
   "outputs": [],
   "source": [
    "sample = normal.sample(sample_shape=[3,4])\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-0pNd9tL-0o"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "We can query the **dimensionlity** of a tensor with the ``shape`` property\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dk2ebGoYL-0p",
    "outputId": "d553bd14-40e5-436a-d069-71cbff41d935"
   },
   "outputs": [],
   "source": [
    "sample = normal.sample(sample_shape=[3,4,5])\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsVjombqL-0p"
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "Operations, like **log-likelihood**, are defined over tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06G293JdL-0p",
    "outputId": "0df20f93-17dc-4f9a-eb0e-7ace95dbb896"
   },
   "outputs": [],
   "source": [
    "normal.log_prob(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3v2rpRAL-0q",
    "outputId": "0eb47a0c-2d77-4a1b-c497-f7c7fa8cc8fd"
   },
   "outputs": [],
   "source": [
    "torch.sum(normal.log_prob(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zErtSTzYL-0q"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "Multiple distributions can be embedded in single object. Below we define three Normal distributions with different means but the same scale in a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEcgGuTqL-0q",
    "outputId": "87ab00ff-0912-43b2-b436-d0a41623ff0c"
   },
   "outputs": [],
   "source": [
    "normal = dist.Normal(torch.tensor([1.,2.,3.]),1.)\n",
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cRRDgTbL-0r",
    "outputId": "c3cb91db-4df7-4c31-c7af-cbefa0c00fa6"
   },
   "outputs": [],
   "source": [
    "normal.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hji5mTnhL-0r",
    "outputId": "81f829da-251b-451c-8ada-231c504ed564"
   },
   "outputs": [],
   "source": [
    "normal.log_prob(normal.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "### **<span style=\"color:red\">Exercise: Open the notebook and play around</span>**\n",
    "\n",
    "* Test that everything works.\n",
    "* Play a bit with the code in Section 1 of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drChKHsWJ--U"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV-iBl4xL-0r"
   },
   "source": [
    "# 2. **Pyro’s models**:\n",
    "\n",
    "---\n",
    "* In Pyro, a probabilistic model is defined as a **stochastic function** (i.e. every time it is run, it returns a new sample).\n",
    "\n",
    "* Each random variable is associated with a **primitive stochastic function** using the construct ``pyro.sample(...)``.\n",
    "---\n",
    "\n",
    "\n",
    "### 2.1 A Temperature Model\n",
    "\n",
    "\n",
    "\n",
    "As initial running example, we consider the problem of **modelling the temperature**. We first start with a simple model where temperture is modeled using a random Normal variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcU2EmBYL-0s",
    "outputId": "85b746ff-d42c-4f76-bb0b-36e20459ded8"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
    "    return temp\n",
    "\n",
    "print(model())\n",
    "print(model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0pVeOVpL-0s"
   },
   "source": [
    "See how the model is a stochastic function which **returns a different value everytime it is invoked**. \n",
    "\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0biYXEVL-0s"
   },
   "source": [
    "### 2.2 A Temperature-Sensor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp6wefVaLCnx"
   },
   "source": [
    "In Pyro, a stochastic method is defined as a composition of primitive stochastic functions.\n",
    "\n",
    "*The temperature Model:* \n",
    "\n",
    "We consider the relation between the temperature and a sensor. \n",
    "  * The temperature sensor gives **noisy observations** about the real temperature.\n",
    "  * The **error** of the sensor's measurements **is known**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpxheEx-L-0t",
    "outputId": "5b1a9091-5f3c-46e7-dfc6-5dbae839d9ea"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
    "    sensor = pyro.sample('sensor', dist.Normal(temp, 1.0))\n",
    "    return (temp, sensor)\n",
    "\n",
    "out1 = model()\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "pyro.render_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSXTeNtqL-0t"
   },
   "source": [
    "The above method defines a joint probability distribution:\n",
    "$$p(sensor, temp) = p(sensor|temp)p(temp)$$\n",
    "\n",
    "\n",
    "In this case, we have a simple dependency between the variables. But, as we are in a PPL, dependencies can be expressed in terms of complex deterministic functions (more examples later).\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCayVyTsL-0t"
   },
   "source": [
    "# 3. **Pyro’s inference** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyC3v0cyL-0u"
   },
   "source": [
    "### Auxiliary inference functions\n",
    "\n",
    "To make inference on Pyro, we will use a variational inference method, which performs gradient-based optimization to solve the inference problem. More details on variational inference will follow in the next lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arZOTC7gL-0u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions import constraints\n",
    "from pyro.optim import SGD\n",
    "from pyro.infer import Trace_ELBO\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.contrib.autoguide import AutoNormal\n",
    "\n",
    "\n",
    "def svi(model, obs, guide=None, num_steps = 500, plot = False, verbose=False, lr=0.01):\n",
    "    \n",
    "    torch.manual_seed(999)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    if guide is None:\n",
    "        guide = AutoNormal(model)\n",
    "    \n",
    "    svi = pyro.infer.SVI(model=model,\n",
    "                         guide=guide,\n",
    "                         optim=SGD({\"lr\": lr, \"momentum\":0.1}),\n",
    "                         loss=Trace_ELBO())\n",
    "\n",
    "    losses, a,b  = [], [], []\n",
    "    \n",
    "    for t in range(num_steps):\n",
    "        losses.append(svi.step(obs))\n",
    "        if t%100==0:\n",
    "            print('Step: '+str(t)+'. Loss: ' +str(losses[-1]))\n",
    "            \n",
    "\n",
    "    if (plot):\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"ELBO\")\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"loss\");\n",
    "        plt.show()\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Inference results:\")\n",
    "        for name, value in pyro.get_param_store().items():\n",
    "            print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovLJGQtcPlBt"
   },
   "source": [
    "A few notes on guides:\n",
    "* To make inference in Pyro over a given model we need to define a *guide*, this *guide* has the same signature as its counterpart model. \n",
    "\n",
    "* The guide must provide samples for those variables of the model which are not observed. Again the ``pyro.sample`` construct. \n",
    "\n",
    "* Guides are also parametrized using Pyro's parameters (``pyro.param``), so the variational inference algorithm will optimize these parameters. \n",
    "\n",
    "* All of this will be explained in detail during the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkkHJOFBL-0u"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "### 3.1  Conditioning on a single observation\n",
    "\n",
    "Now, we continue with the last model defined in section 2.2, and assume we have a sensor reading and we want to compute the posterior distribution over the real temperature. \n",
    "\n",
    "This can be achived by introducing **observations in the random variable** with the keyword ``obs=``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSzNRm7wL-0v"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "obs = {'sensor': torch.tensor(18.0)}\n",
    "\n",
    "def model(obs):\n",
    "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
    "    sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "pyro.render_model(model, model_args=(obs, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH3PgF4wL-0w"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "Inference is made using the previously defined auxiliary functions, ``svi`` and ``guide``. \n",
    "\n",
    "We can query the **posterior probability distribution**: \n",
    "\n",
    "\n",
    "$$p(temp | sensor=18)=\\frac{p(sensor=18|temp)p(temp)}{\\int p(sensor=18|temp)p(temp) dtemp}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "VObMyZQ_L-0w",
    "outputId": "364de9bd-0057-4a6e-86fe-5581363bfb96"
   },
   "outputs": [],
   "source": [
    "#Run inference\n",
    "svi(model,obs, plot=True)\n",
    "\n",
    "#Print results\n",
    "print(\"P(Temperature|Sensor=18.0) = \")\n",
    "print(dist.Normal(pyro.param(\"AutoNormal.locs.temp\").item(), pyro.param(\"AutoNormal.scales.temp\").item()))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAbW6UoTL-0x"
   },
   "source": [
    "### 3.2  Learning from a bunch of observations\n",
    "\n",
    "Let us assume we have a **set of observations** about the temperature at different time steps. \n",
    "\n",
    "* Following a probabilistic modelling approach, we define a **set of random variables**.\n",
    "\n",
    "* One random variable for each **observation**, using a standard ``for-loop``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2bPy-D4L-0x"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
    "\n",
    "def model(obs):\n",
    "    for i in range(obs['sensor'].shape[0]):\n",
    "        temp = pyro.sample(f'temp_{i}', dist.Normal(15.0, 2.0))\n",
    "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "pyro.render_model(model, model_args=(obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference\n",
    "svi(model, obs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjcPTM1PL-0x"
   },
   "source": [
    "---\n",
    "What if we do **not know the mean temperature** (as illustrated in the graphical model below)?\n",
    "<center>\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/PGM-Tem_sensor4.png?raw=1\" alt=\"Drawing\" width=\"150\">\n",
    "</center>\n",
    "\n",
    "* We can **infer the parameter from the data** by, e.g., using a **maximum likelihood** approach,\n",
    "$$ \\mu_{t} = \\arg\\max_\\mu \\ln p(s_1,\\ldots,s_n|\\mu) = \\arg\\max_\\mu \\prod_i \\int_{t_i} p(s_i|t_i)p(t_i|\\mu) dt_i, $$ where $s_i$ and $t_i$ denote the sensor reading and the real temperature at time $i$. \n",
    "\n",
    "For now we do not consider the **underlying inference problem** We just define the model and let the **PPL's engine** do the work for us. \n",
    "* We use Pyro's parameters (defined as ``pyro.param``), which are free variables we can optimize. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXEFGMkzL-0x"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
    "\n",
    "def model(obs):\n",
    "    mean_temp = pyro.param('mean_temp', torch.tensor(15.0))\n",
    "    for i in range(obs['sensor'].shape[0]):\n",
    "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
    "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "pyro.render_model(model, model_args=(obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEfOM8zWL-0y",
    "outputId": "3a17d682-efe2-46a3-8bb7-2ac82b75986f"
   },
   "outputs": [],
   "source": [
    "#Run inference\n",
    "svi(model, obs)\n",
    "\n",
    "#Print results\n",
    "print(\"Estimated Mean Temperature (MLE):\")\n",
    "mle_mean_temp = pyro.param(\"mean_temp\").item() \n",
    "print(mle_mean_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tiCwbfJwL-0y"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=true\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "Instead of performing *maximum likelihood* learning, we can perform **Bayesian learning**.\n",
    "* We treat the unknown quantity as a **random variable**.\n",
    "\n",
    "* This model can be graphically represented as follows:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/PGM-Tem-Sensor2.png?raw=1\" alt=\"Drawing\" width=\"150\">\n",
    "</center>\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaTdLm6ML-0y"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
    "\n",
    "def model(obs):\n",
    "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
    "    for i in range(obs['sensor'].shape[0]):\n",
    "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
    "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "pyro.render_model(model, model_args=(obs, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJfVNZFBL-0y"
   },
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "We perform inference over this model (see Slides from the last lecture):\n",
    "\n",
    " $$ p(\\mu_t | s_1,\\ldots, s_n)=\\frac{p(\\mu_t)\\prod_{i=1}^n \\int p(s_i|t_i)p(t_i|\\mu_t)dt_i }{\\int \\prod_{i=1}^n p(s_i|\\mu_t)p(\\mu_t) d\\mu} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0YiqM36L-0z",
    "outputId": "dae46c1e-5583-4c73-9ecf-39efedf730f2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "        \n",
    "#Run inference\n",
    "start = time.time()\n",
    "svi(model, obs)\n",
    "model\n",
    "\n",
    "#Print results\n",
    "print(\"P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\")\n",
    "print(dist.Normal(pyro.param(\"AutoNormal.locs.mean_temp\").item(), pyro.param(\"AutoNormal.scales.mean_temp\").item()))\n",
    "print(\"\")\n",
    "end = time.time()\n",
    "print(f\"{(end - start)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFKoGLcnL-0z"
   },
   "source": [
    "As we also saw in the last lecture, the result of the learning is **not a point estimate**. Instead we have a **posterior distribution**, which captures the **uncertainty** about the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ES_yHXNKL-0z",
    "outputId": "6ff35c3e-a19b-4936-ba6e-9947c9b237d1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "mu = pyro.param(\"AutoNormal.locs.mean_temp\").item()\n",
    "scale = pyro.param(\"AutoNormal.scales.mean_temp\").item()\n",
    "x = np.linspace(mu - 3*scale, mu + 3*scale, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, scale), label='Posterior over $\\mu$')\n",
    "point = mle_mean_temp # Previously calculated above\n",
    "plt.plot([point, point],[0., 1.], label='MLE point estimate of $\\mu$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1SXUdMtUL-00"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/PGM-Lab/probai-2021-pyro/main/Day1/Figures/blue.png\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "### 3.3 The use of ``plate`` construct\n",
    "\n",
    "* Pyro can exploit **conditional independencies and vectorization** to make inference much faster. \n",
    "\n",
    "* This can be done with the construct **``plate``**. \n",
    "\n",
    "* With this construct, we can indicate that the variables $s_i$ and $t_i$ are **conditionally indepdendent** from other variables $s_j$ and $t_j$ given $\\mu_t$. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/PGM-Tem-Sensor2.png?raw=1\" alt=\"Drawing\" width=\"150\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LlQKqp4L-00"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
    "\n",
    "def model(obs):\n",
    "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
    "    with pyro.plate('a', obs['sensor'].shape[0]):\n",
    "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
    "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAh8vLjLL-00"
   },
   "source": [
    "The ``plate`` construct reflects the standard notational use in graphical models denoting the **repetition of some parts of of the graph**. \n",
    "<center>\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/PGM-Tem-Sensor3.png?raw=1\" alt=\"Drawing\" width=\"250\">\n",
    "</center>\n",
    "\n",
    "We can here make a distinction between **local** and **global** random variables: \n",
    "\n",
    "* **Local random variables** caputure **specific information** about the $i$-th data sample (i.e. the real temperature at this moment in time).\n",
    "\n",
    "* **Global random variables** capture **common information** about all the data samples (i.e. the average temperature of all data samples). \n",
    "\n",
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "Observe how inference in this model is much **faster**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASYtP3j0L-01",
    "outputId": "01793daa-19bd-4552-8486-392af3eeb5e6"
   },
   "outputs": [],
   "source": [
    "#Run inference\n",
    "start = time.time()\n",
    "svi(model, obs)\n",
    "\n",
    "#Print results\n",
    "print(\"P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\")\n",
    "print(dist.Normal(pyro.param(\"AutoNormal.locs.mean_temp\").item(), pyro.param(\"AutoNormal.scales.mean_temp\").item()))\n",
    "print(\"\")\n",
    "end = time.time()\n",
    "print(f\"{(end - start)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/PGM-Lab/probai-2021-pyro/blob/main/Day1/Figures/blue.png?raw=1\" alt=\"Drawing\" width=2000 height=20>\n",
    "\n",
    "\n",
    "### **<span style=\"color:red\">Exercise 2: </span>The role of *prior distributions* in learning**\n",
    "\n",
    "In this case we just want to illustrate how the output of learning depends of the particular prior we introduce in the model. Play with different options and extract conclusions:\n",
    "\n",
    "1. What happens if we change the mean of the prior?\n",
    "2. What happens if we change the scale of the prior?\n",
    "3. What happens to the posterior if the number of data samples deacreases and increases?\n",
    "\n",
    "The code below might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "5OWLg5tvL-01",
    "outputId": "c6e80f76-72af-41ec-a581-de6c2421fb59"
   },
   "outputs": [],
   "source": [
    "#The observatons   \n",
    "sample_size = 10\n",
    "obs = {'sensor': torch.tensor(np.random.normal(18,2,sample_size))}\n",
    "\n",
    "def model(obs):\n",
    "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
    "    with pyro.plate('N='+str(obs['sensor'].shape[0]), obs['sensor'].shape[0]):\n",
    "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
    "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])\n",
    "\n",
    "#Run inference\n",
    "svi(model, obs)\n",
    "\n",
    "#Print results\n",
    "print(\"P(Temperature|Sensor=18.0) = \")\n",
    "print(dist.Normal(pyro.param(\"AutoNormal.locs.mean_temp\").item(), pyro.param(\"AutoNormal.scales.mean_temp\").item()))\n",
    "\n",
    "x = np.linspace(16, 20, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, pyro.param(\"AutoNormal.locs.mean_temp\").item(), pyro.param(\"AutoNormal.scales.mean_temp\").item()), label='Posterior')\n",
    "point = 18\n",
    "plt.plot([point, point],[0., 1.], label='Point Estimate')\n",
    "plt.xlim(16,20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "solutions_PPLs_Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
